package sc.iview.commands.demo.advanced

import org.joml.Vector3f
import org.joml.Matrix4f
import org.joml.Quaternionf
import graphics.scenery.utils.extensions.*
import graphics.scenery.utils.lazyLogger
import org.slf4j.LoggerFactory
import java.io.File
import kotlin.math.sqrt

/**
 * <Description>
 *
 * @author Ulrik GÃ¼nther <hello@ulrik.is>
 */
class HedgehogAnalysis(val spines: List<SpineMetadata>, val localToWorld: Matrix4f) {

	private val logger by lazyLogger()
	
	val timepoints = LinkedHashMap<Int, ArrayList<SpineMetadata>>()

	var avgConfidence = 0.0f
		private set
	var totalSampleCount = 0
		private set

	data class Track(
		val points: List<Pair<Vector3f, SpineGraphVertex>>,
		val confidence: Float
	)

	init {
		logger.info("Starting analysis with ${spines.size} spines")

		spines.forEach { spine ->
			val timepoint = spine.timepoint
			val current = timepoints[timepoint]

			if(current == null) {
				timepoints[timepoint] = arrayListOf(spine)
			} else {
				current.add(spine)
			}

			avgConfidence += spine.confidence
			totalSampleCount++
		}

		avgConfidence /= totalSampleCount
	}

	/**
	 * From a [list] of Floats, return both the index of local maxima, and their value,
	 * packaged nicely as a Pair<Int, Float>
	 */
	private fun localMaxima(list: List<Float>): List<Pair<Int, Float>> {
		return list.windowed(3, 1).mapIndexed { index, l ->
			val left = l[0]
			val center = l[1]
			val right = l[2]

			// we have a match at center
			if (left < center && center > right) {
				index * 1 + 1 to center
			} else {
				null
			}
		}.filterNotNull()
	}

	data class SpineGraphVertex(val timepoint: Int,
								val position: Vector3f,
								val worldPosition: Vector3f,
								val index: Int,
								val value: Float,
								val metadata : SpineMetadata,
								var previous: SpineGraphVertex? = null,
								var next: SpineGraphVertex? = null) {

		fun distance(): Float {
			val n = next
			return if(n != null) {
				val t = (n.worldPosition - this.worldPosition)
				sqrt(t.x*t.x + t.y*t.y + t.z*t.z)
			} else {
				0.0f
			}
		}

		fun drop() {
			previous?.next = next
			next?.previous = previous
		}

		override fun toString() : String {
			return "SpineGraphVertex for t=$timepoint, pos=$position,index=$index, worldPos=$worldPosition, value=$value"
		}
	}

	fun Iterable<Float>.stddev() = sqrt((this.map { (it - this.average()) * (it - this.average()) }.sum() / this.count()))

	fun Vector3f.toQuaternionf(forward: Vector3f = Vector3f(0.0f, 0.0f, -1.0f)): Quaternionf {
		val cross = forward.cross(this)
		val q = Quaternionf(cross.x(), cross.y(), cross.z(), this.dot(forward))

		val x = sqrt((q.w + sqrt(q.x*q.x + q.y*q.y + q.z*q.z + q.w*q.w)) / 2.0f)

		return Quaternionf(q.x/(2.0f * x), q.y/(2.0f * x), q.z/(2.0f * x), x)
	}

	data class VertexWithDistance(val vertex: SpineGraphVertex, val distance: Float)

	fun run(): Track? {

		val startingThreshold = 0.002f
		val localMaxThreshold = 0.001f
		val zscoreThreshold = 2.0f
		val removeTooFarThreshold = 5.0f

		if(timepoints.isEmpty()) {
			return null
		}


		//step1: find the startingPoint by using startingthreshold
		val startingPoint = timepoints.entries.firstOrNull { entry ->
			entry.value.any { metadata -> metadata.samples.filterNotNull().any { it > startingThreshold } }
		} ?: return null

		logger.info("Starting point is ${startingPoint.key}/${timepoints.size} (threshold=$startingThreshold)")

		// filter timepoints, remove all before the starting point
		timepoints.filter { it.key > startingPoint.key }
				.forEach { timepoints.remove(it.key) }

		logger.info("${timepoints.size} timepoints left")

		fun gaussSmoothing(samples: List<Float>, iterations: Int): List<Float> {
			var smoothed = samples.toList()
			val kernel = listOf(0.25f, 0.5f, 0.25f)
			for (i in 0 until iterations) {
				val newSmoothed = ArrayList<Float>(smoothed.size)
				// Handle the first element
				newSmoothed.add(smoothed[0] * 0.75f + smoothed[1] * 0.25f)
				// Apply smoothing to the middle elements
				for (j in 1 until smoothed.size - 1) {
					val value = kernel[0] * smoothed[j-1] + kernel[1] * smoothed[j] + kernel[2] * smoothed[j+1]
					newSmoothed.add(value)
				}
				// Handle the last element
				newSmoothed.add(smoothed[smoothed.size - 2] * 0.25f + smoothed[smoothed.size - 1] * 0.75f)

				smoothed = newSmoothed
			}
			return smoothed
		}

		//step2: find the maxIndices along the spine
		// yo dawg, this will be a list of lists, where each entry in the first-level list
		// corresponds to a time point, which then contains a list of vertices within that timepoint.
		val candidates: List<List<SpineGraphVertex>> = timepoints.map { tp ->
			val vs = tp.value.mapIndexedNotNull { i, spine ->
				// determine local maxima (and their indices) along the spine, aka, actual things the user might have
				// seen when looking into the direction of the spine
				val maxIndices = localMaxima(spine.samples.filterNotNull())
				logger.debug("Local maxima at ${tp.key}/$i are: ${maxIndices.joinToString(",")}")

				// if there actually are local maxima, generate a graph vertex for them with all the necessary metadata
				if(maxIndices.isNotEmpty()) {
					//maxIndices.
//                  filter the maxIndices which are too far away, which can be removed
					//filter { it.first <1200}.
					maxIndices.map { index ->
						logger.debug("Generating vertex at index $index")
						val position = Vector3f(spine.localEntry).add((Vector3f(spine.localDirection).mul(index.first.toFloat())))
						val worldPosition = localToWorld.transform((Vector3f(position)).xyzw()).xyz()
						SpineGraphVertex(tp.key,
								position,
								worldPosition,
								index.first,
								index.second,
								spine)

					}
				} else {
					null
				}
			}
			vs
		}.flatten()

		logger.info("SpineGraphVertices extracted")

		// step3: connect localMaximal points between 2 candidate spines according to the shortest path principle
		// get the initial vertex, this one is assumed to always be in front, and have a local maximum - aka, what
		// the user looks at first is assumed to be the actual cell they want to track
		val initial = candidates.first().first { it.value > startingThreshold }
		var current = initial
		var shortestPath = candidates.drop(1).mapIndexedNotNull { time, vs ->
			// calculate world-space distances between current point, and all candidate
			// vertices, sorting them by distance
			val vertices = vs
					.filter { it.value > localMaxThreshold }
					.map { vertex ->
						val t = current.worldPosition - vertex.worldPosition
						val distance = t.length()
						VertexWithDistance(vertex, distance)
					}
					.sortedBy { it.distance }

			val closest = vertices.firstOrNull()
			if(closest != null && closest.distance > 0) {
				// create a linked list between current and closest vertices
				current.next = closest.vertex
				closest.vertex.previous = current
				current = closest.vertex
				current
			} else {
				null
			}
		}.toMutableList()

		// calculate average path lengths over all
		val beforeCount = shortestPath.size
		var avgPathLength = shortestPath.map { it.distance() }.average().toFloat()
		var stdDevPathLength = shortestPath.map { it.distance() }.stddev().toFloat()
		logger.info("Average path length=$avgPathLength, stddev=$stdDevPathLength")

		fun zScore(value: Float, m: Float, sd: Float) = ((value - m)/sd)

		//step4: if some path is longer than multiple average length, it should be removed
		while (shortestPath.any { it.distance() >= removeTooFarThreshold * avgPathLength }) {
			shortestPath = shortestPath.filter { it.distance() < removeTooFarThreshold * avgPathLength }.toMutableList()
			shortestPath.windowed(3, 1, partialWindows = true).forEach {
				// this reconnects the neighbors after the offending vertex has been removed
				it.getOrNull(0)?.next = it.getOrNull(1)
				it.getOrNull(1)?.previous = it.getOrNull(0)
				it.getOrNull(1)?.next = it.getOrNull(2)
				it.getOrNull(2)?.previous = it.getOrNull(1)
			}

		}

		// recalculate statistics after offending vertex removal
		avgPathLength = shortestPath.map { it.distance() }.average().toFloat()
		stdDevPathLength = shortestPath.map { it.distance() }.stddev().toFloat()

		//step5: remove some vertices according to zscoreThreshold
		var remaining = shortestPath.count { zScore(it.distance(), avgPathLength, stdDevPathLength) > zscoreThreshold }
		logger.info("Iterating: ${shortestPath.size} vertices remaining, with $remaining failing z-score criterion")
		while(remaining > 0) {
			val outliers = shortestPath
					.filter { zScore(it.distance(), avgPathLength, stdDevPathLength) > zscoreThreshold }
					.map {
						val idx = shortestPath.indexOf(it)
						listOf(idx-1,idx,idx+1)
					}.flatten()

			shortestPath = shortestPath.filterIndexed { index, _ -> index !in outliers }.toMutableList()
			remaining = shortestPath.count { zScore(it.distance(), avgPathLength, stdDevPathLength) > zscoreThreshold }

			shortestPath.windowed(3, 1, partialWindows = true).forEach {
				it.getOrNull(0)?.next = it.getOrNull(1)
				it.getOrNull(1)?.previous = it.getOrNull(0)
				it.getOrNull(1)?.next = it.getOrNull(2)
				it.getOrNull(2)?.previous = it.getOrNull(1)
			}
			logger.info("Iterating: ${shortestPath.size} vertices remaining, with $remaining failing z-score criterion")
		}

		val afterCount = shortestPath.size
		logger.info("Pruned ${beforeCount - afterCount} vertices due to path length")
		val singlePoints = shortestPath
				.groupBy { it.timepoint }
				.mapNotNull { vs -> vs.value.maxByOrNull{ it.metadata.confidence } }
				.filter {
					it.metadata.direction.dot(it.previous!!.metadata.direction) > 0.5f
				}


		logger.info("Returning ${singlePoints.size} points")


		return Track(singlePoints.map { it.position to it}, avgConfidence)
	}

	companion object {
		private val logger by lazyLogger(System.getProperty("scenery.LogLevel", "info"))

		fun fromIncompleteCSV(csv: File, separator: String = ","): HedgehogAnalysis {
			logger.info("Loading spines from incomplete CSV at ${csv.absolutePath}")

			val lines = csv.readLines()
			val spines = ArrayList<SpineMetadata>(lines.size)

			lines.drop(1).forEach { line ->
				val tokens = line.split(separator)
				val timepoint = tokens[0].toInt()
				val confidence = tokens[1].toFloat()
				val samples = tokens.subList(2, tokens.size - 1).map { it.toFloat() }

				val currentSpine = SpineMetadata(
						timepoint,
						Vector3f(0.0f),
						Vector3f(0.0f),
						0.0f,
						Vector3f(0.0f),
						Vector3f(0.0f),
						Vector3f(0.0f),
						Vector3f(0.0f),
						Quaternionf(),
						Vector3f(0.0f),
						confidence,
						samples)

				spines.add(currentSpine)
			}

			return HedgehogAnalysis(spines, Matrix4f())
		}

		private fun String.toVector3f(): Vector3f {
			val array = this.replace("(", "").replace(")", "").trim().split(" ").filterNot { it == ""}

			if (array[0] == "+Inf" || array[0] == "-Inf")
				return Vector3f(0.0f,0.0f,0.0f)

			return Vector3f(array[0].toFloat(),array[1].toFloat(),array[2].toFloat())
		}

		private fun String.toQuaternionf(): Quaternionf {
			val array = this.replace("(", "").replace(")", "").trim().split(" ").filterNot { it == ""}
			return Quaternionf(array[0].toFloat(), array[1].toFloat(), array[2].toFloat(), array[3].toFloat())
		}
		fun fromCSVWithMatrix(csv: File, matrix4f: Matrix4f,separator: String = ";"): HedgehogAnalysis {
			logger.info("Loading spines from complete CSV with Matrix at ${csv.absolutePath}")

			val lines = csv.readLines()
			val spines = ArrayList<SpineMetadata>(lines.size)
			logger.info("lines number: " + lines.size)
			lines.drop(1).forEach { line ->
				val tokens = line.split(separator)
				val timepoint = tokens[0].toInt()
				val origin = tokens[1].toVector3f()
				val direction = tokens[2].toVector3f()
				val localEntry = tokens[3].toVector3f()
				val localExit = tokens[4].toVector3f()
				val localDirection = tokens[5].toVector3f()
				val headPosition = tokens[6].toVector3f()
				val headOrientation = tokens[7].toQuaternionf()
				val position = tokens[8].toVector3f()
				val confidence = tokens[9].toFloat()
				val samples = tokens.subList(10, tokens.size - 1).map { it.toFloat() }

				val currentSpine = SpineMetadata(
						timepoint,
						origin,
						direction,
						0.0f,
						localEntry,
						localExit,
						localDirection,
						headPosition,
						headOrientation,
						position,
						confidence,
						samples)

				spines.add(currentSpine)
			}

			return HedgehogAnalysis(spines, matrix4f)
		}

		fun fromCSV(csv: File, separator: String = ";"): HedgehogAnalysis {
			logger.info("Loading spines from complete CSV at ${csv.absolutePath}")

			val lines = csv.readLines()
			val spines = ArrayList<SpineMetadata>(lines.size)

			lines.drop(1).forEach { line ->
				val tokens = line.split(separator)
				val timepoint = tokens[0].toInt()
				val origin = tokens[1].toVector3f()
				val direction = tokens[2].toVector3f()
				val localEntry = tokens[3].toVector3f()
				val localExit = tokens[4].toVector3f()
				val localDirection = tokens[5].toVector3f()
				val headPosition = tokens[6].toVector3f()
				val headOrientation = tokens[7].toQuaternionf()
				val position = tokens[8].toVector3f()
				val confidence = tokens[9].toFloat()
				val samples = tokens.subList(10, tokens.size - 1).map { it.toFloat() }

				val currentSpine = SpineMetadata(
						timepoint,
						origin,
						direction,
						0.0f,
						localEntry,
						localExit,
						localDirection,
						headPosition,
						headOrientation,
						position,
						confidence,
						samples)

				spines.add(currentSpine)
			}

			return HedgehogAnalysis(spines, Matrix4f())
		}
	}
}

fun main(args: Array<String>) {
	val logger = LoggerFactory.getLogger("HedgehogAnalysisMain")

	val file = File("C:\\Users\\lanru\\Desktop\\BionicTracking-generated-2021-11-29 19.37.43\\Hedgehog_1_2021-11-29 19.38.32.csv")
	val analysis = HedgehogAnalysis.fromCSV(file)
	val results = analysis.run()
	logger.info("Results: \n$results")
}
